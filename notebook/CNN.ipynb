{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1d76d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from shutil import unpack_archive\n",
    "from collections import OrderedDict\n",
    "from keras_preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fc956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN (object):\n",
    "    def __init__(self, dataset_path, img_width, img_height, batch_size, epochs, num_classes, model_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def train(self):\n",
    "        # Data augmentation\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        self.read_clean_data()\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            self.dataset_path + \"output/multi_train\",\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        validation_generator = test_datagen.flow_from_directory(\n",
    "            self.dataset_path + \"output/multi_val/\",\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        testing_generator = test_datagen.flow_from_directory(\n",
    "            self.dataset_path + \"output/multi_test/\",\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical'            \n",
    "        )\n",
    "\n",
    "        # Model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(96, (7, 7), strides=(2, 2), padding='same', input_shape=(self.img_width, self.img_height, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        model.add(Conv2D(256, (1, 1), strides=(1, 1), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        model.add(Conv2D(384, (1, 1), strides=(1, 1), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(4096))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        #modelo de treinamento reconhecimento de faces usando o modelo de treinamento do AlexNet\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        # Training\n",
    "        sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "        checkpointer = ModelCheckpoint(filepath=self.model_path, \n",
    "                                        verbose=1, \n",
    "                                        save_best_only=True, \n",
    "                                        monitor='val_loss',\n",
    "                                        save_freq='epoch')\n",
    "        model.fit_generator( train_generator, \n",
    "                            steps_per_epoch=train_generator.n // self.batch_size, \n",
    "                            epochs=self.epochs, \n",
    "                            validation_data=validation_generator, \n",
    "                            validation_steps=testing_generator.n // self.batch_size, \n",
    "                            callbacks=[checkpointer])\n",
    "\n",
    "        # Save model\n",
    "        model.save(self.model_path)\n",
    "\n",
    "    def read_clean_data(self):\n",
    "        lfw_allnames = pd.read_csv(self.dataset_path + \"lfw_allnames.csv\")\n",
    "\n",
    "        image_paths = lfw_allnames.loc[lfw_allnames.index.repeat(lfw_allnames['images'])]\n",
    "        image_paths['image_path'] = 1 + image_paths.groupby('name').cumcount()\n",
    "        image_paths['image_path'] = image_paths.image_path.apply(lambda x: '{0:0>4}'.format(x))\n",
    "        image_paths['image_path'] = image_paths.name + \"/\" + image_paths.name + \"_\" + image_paths.image_path + \".jpg\"\n",
    "        image_paths = image_paths.drop(\"images\",axis=1)\n",
    "\n",
    "        # Separate classes\n",
    "        multi_data = pd.concat([image_paths[image_paths.name==\"George_W_Bush\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Colin_Powell\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Tony_Blair\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Donald_Rumsfeld\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Gerhard_Schroeder\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Ariel_Sharon\"].sample(75)])\n",
    "\n",
    "        print(\"Multi_Data \",len(multi_data))\n",
    "\n",
    "        multi_train, multi_test = train_test_split(multi_data, test_size=0.3)\n",
    "        multi_train, multi_val = train_test_split(multi_train,test_size=0.3)\n",
    "\n",
    "        self.directory_mover(multi_train,\"multi_train/\")\n",
    "        self.directory_mover(multi_val,\"multi_val/\")\n",
    "        self.directory_mover(multi_test,\"multi_test/\")\n",
    "\n",
    "\n",
    "    def directory_mover(self,data,dir_name):\n",
    "        co = 0\n",
    "        for image in data.image_path:\n",
    "            # create top directory\n",
    "            if not os.path.exists(os.path.join(self.dataset_path + 'output/',dir_name)):\n",
    "                shutil.os.mkdir(os.path.join(self.dataset_path + 'output/',dir_name))\n",
    "\n",
    "            data_type = data[data['image_path'] == image]['name']\n",
    "            data_type = str(list(data_type)[0])\n",
    "            if not os.path.exists(os.path.join(self.dataset_path + 'output/',dir_name,data_type)):\n",
    "                shutil.os.mkdir(os.path.join(self.dataset_path + 'output/',dir_name,data_type))\n",
    "            path_from = os.path.join(self.dataset_path + 'lfw-deepfunneled/',image)\n",
    "            path_to = os.path.join(self.dataset_path + 'output/',dir_name,data_type)\n",
    "            # print(path_to)\n",
    "            shutil.copy(path_from, path_to)\n",
    "            # print('Moved {} to {}'.format(image,path_to))\n",
    "            co += 1\n",
    "\n",
    "        print('Moved {} images to {} folder.'.format(co,dir_name))\n",
    "\n",
    "\n",
    "    def clean(self):\n",
    "        # Clean image used for testing\n",
    "        if \"multi_train\" in os.listdir(self.dataset_path + \"output/\"):\n",
    "            shutil.rmtree(self.dataset_path + \"output/multi_train\")\n",
    "        if \"multi_val\" in os.listdir(self.dataset_path + \"output/\"):\n",
    "            shutil.rmtree(self.dataset_path + \"output/multi_val\")\n",
    "        if \"multi_test\" in os.listdir(self.dataset_path + \"output/\"):\n",
    "            shutil.rmtree(self.dataset_path + \"output/multi_test\")\n",
    "\n",
    "    def get_stats(self):\n",
    "        multi_test_names = []\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        multi_test_set = test_datagen.flow_from_directory(\n",
    "            self.dataset_path + \"output/multi_test/\",\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical'            \n",
    "        )\n",
    "\n",
    "        for i in range(len(multi_test_set.filenames)):\n",
    "            multi_test_names.append(multi_test_set.filenames[i])\n",
    "        for i in range(len(multi_test_names)):\n",
    "            multi_test_names[i] = multi_test_names[i].split(\"/\")[0]\n",
    "\n",
    "        multi_test_name_order = list(OrderedDict.fromkeys(multi_test_names))\n",
    "        for i in range(len(multi_test_name_order)):\n",
    "            multi_test_name_order[i] = multi_test_name_order[i].replace(\"\\\\\",\"/\")\n",
    "            \n",
    "        predictions_values = []\n",
    "        predictions_len = []\n",
    "        for i in range(len(multi_test_name_order)):\n",
    "            prediction = self.predict(self.dataset_path + \"output/multi_test/\" + multi_test_name_order[i] + \"/\")\n",
    "            predictions_values += prediction\n",
    "            predictions_len += [i] * len(prediction)\n",
    "\n",
    "        \n",
    "        multi_predic_frame = pd.DataFrame(list(zip(predictions_values,predictions_len)), columns=['Predictions','Actual'])\n",
    "        stats = self.prec_acc(multi_predic_frame)\n",
    "        print(\"Precision: \" + str(stats[1]))\n",
    "        print(\"Recall: \" + str(stats[2]))\n",
    "        print(\"Classes: \" + multi_test_name_order)\n",
    "        \n",
    "    def predict(self, img_path):\n",
    "        preds = []\n",
    "        model = keras.models.load_model(self.model_path)\n",
    "        for img_name in os.listdir(img_path):\n",
    "            img = image.load_img(img_path + str(img_name), target_size=(self.img_width, self.img_height))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            #x = preprocess_input(x)\n",
    "            result = model.predict(x)\n",
    "            preds.append(result)\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def prec_acc(self, df):\n",
    "        precision = []\n",
    "        accuracy = []\n",
    "        recall = []\n",
    "        for i in range(len(set(df.Predictions))):\n",
    "            tp = df[np.logical_and(df['Actual'] == i, df['Predictions'] == i)].shape[0]\n",
    "            tn = df[np.logical_and(df['Actual'] != i, df['Predictions'] != i)].shape[0]\n",
    "            fp = df[np.logical_and(df['Actual'] != i, df['Predictions'] == i)].shape[0]\n",
    "            fn = df[np.logical_and(df['Actual'] == i, df['Predictions'] != i)].shape[0]\n",
    "            total_preds = df.shape[0]\n",
    "            precision.append(tp/(tp + fp))\n",
    "            accuracy.append((tp + tn)/total_preds)\n",
    "            recall.append(tp/(tp + fn))\n",
    "        return(accuracy,precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d94c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_test = CNN(\"../dataset/\",250,250,32,14,6,\"../dataset/output/model/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9235a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi_Data  450\n",
      "Moved 220 images to multi_train/ folder.\n",
      "Moved 95 images to multi_val/ folder.\n",
      "Moved 135 images to multi_test/ folder.\n",
      "Found 220 images belonging to 6 classes.\n",
      "Found 95 images belonging to 6 classes.\n",
      "Found 135 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 10\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "C:\\Users\\Windows 10\\AppData\\Local\\Temp\\ipykernel_19068\\3058827065.py:85: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator( train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 24.3953 - accuracy: 0.2021 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1803419.25000, saving model to ../dataset/output/model\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../dataset/output/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../dataset/output/model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 128s 22s/step - loss: 24.3953 - accuracy: 0.2021 - val_loss: 1803419.2500 - val_accuracy: 0.2105\n",
      "Epoch 2/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 39.2577 - accuracy: 0.1862 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 72s 12s/step - loss: 39.2577 - accuracy: 0.1862\n",
      "Epoch 3/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 24.3236 - accuracy: 0.3032 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 71s 12s/step - loss: 24.3236 - accuracy: 0.3032\n",
      "Epoch 4/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 20.2814 - accuracy: 0.3511 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 73s 12s/step - loss: 20.2814 - accuracy: 0.3511\n",
      "Epoch 5/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 21.6102 - accuracy: 0.3617 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 72s 12s/step - loss: 21.6102 - accuracy: 0.3617\n",
      "Epoch 6/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 17.0340 - accuracy: 0.4043 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 73s 12s/step - loss: 17.0340 - accuracy: 0.4043\n",
      "Epoch 7/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 18.0968 - accuracy: 0.4043 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 71s 12s/step - loss: 18.0968 - accuracy: 0.4043\n",
      "Epoch 8/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 14.4274 - accuracy: 0.4574 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 71s 12s/step - loss: 14.4274 - accuracy: 0.4574\n",
      "Epoch 9/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 16.6643 - accuracy: 0.4043 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 71s 12s/step - loss: 16.6643 - accuracy: 0.4043\n",
      "Epoch 10/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 13.2982 - accuracy: 0.5585 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 71s 12s/step - loss: 13.2982 - accuracy: 0.5585\n",
      "Epoch 11/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 14.2853 - accuracy: 0.5160 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 71s 12s/step - loss: 14.2853 - accuracy: 0.5160\n",
      "Epoch 12/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 15.5721 - accuracy: 0.5573 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 73s 12s/step - loss: 15.5721 - accuracy: 0.5573\n",
      "Epoch 13/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 10.5194 - accuracy: 0.6383WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 75s 12s/step - loss: 10.5194 - accuracy: 0.6383\n",
      "Epoch 14/14\n",
      "6/6 [==============================] - ETA: 0s - loss: 9.3991 - accuracy: 0.6223 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "6/6 [==============================] - 71s 12s/step - loss: 9.3991 - accuracy: 0.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../dataset/output/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../dataset/output/model/assets\n"
     ]
    }
   ],
   "source": [
    "cnn_test.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190b852",
   "metadata": {},
   "source": [
    "# -----------------TESTING---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "972cae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../dataset/\"\n",
    "img_width = 250\n",
    "img_height = 250\n",
    "batch_size = 32\n",
    "epochs = 14\n",
    "num_classes = 6\n",
    "model_path = '../dataset/output/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44df6484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "multi_test_names = []\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "multi_test_set = test_datagen.flow_from_directory(\n",
    "    dataset_path + \"output/multi_test/\",\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79d57057",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(multi_test_set.filenames)):\n",
    "    multi_test_names.append(multi_test_set.filenames[i])\n",
    "for i in range(len(multi_test_names)):\n",
    "    multi_test_names[i] = multi_test_names[i].split(\"\\\\\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12ba1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_test_name_order = list(OrderedDict.fromkeys(multi_test_names))\n",
    "for i in range(len(multi_test_name_order)):\n",
    "    multi_test_name_order[i] = multi_test_name_order[i].replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e2cb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path):\n",
    "    preds = []\n",
    "    model = keras.models.load_model(model_path)\n",
    "    for img_name in os.listdir(img_path):\n",
    "        img = image.load_img(img_path + str(img_name), target_size=(img_width, img_height))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        #x = preprocess_input(x)\n",
    "        result = np.argmax(model.predict(x))\n",
    "        preds.append(result)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "274bc1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 1s 739ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 290ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n"
     ]
    }
   ],
   "source": [
    "m_p0 = predict(dataset_path + \"output/multi_test/\" + multi_test_name_order[0] + \"/\")\n",
    "m_p1 = predict(dataset_path + \"output/multi_test/\" + multi_test_name_order[1] + \"/\")\n",
    "m_p2 = predict(dataset_path + \"output/multi_test/\" + multi_test_name_order[2] + \"/\")\n",
    "m_p3 = predict(dataset_path + \"output/multi_test/\" + multi_test_name_order[3] + \"/\")\n",
    "m_p4 = predict(dataset_path + \"output/multi_test/\" + multi_test_name_order[4] + \"/\")\n",
    "m_p5 = predict(dataset_path + \"output/multi_test/\" + multi_test_name_order[5] + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d242309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predic_frame = pd.DataFrame(list(zip(predictions_values,predictions_len)), columns=['Predictions','Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c7986f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predic_frame_a = pd.DataFrame(list(zip(m_p0 + m_p1 + m_p2 + m_p3 + m_p4 + m_p5,\n",
    "                                                [0] * len(m_p0) + [1] * len(m_p1) + [2] * len(m_p2) + [3] * len(m_p3) + [4] * len(m_p4) + [5] * len(m_p5))),\n",
    "                                       columns = ['Predictions','Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "69d59fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 4, 1, 1, 2, 5, 1, 5, 1, 1, 1, 5, 1, 1]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "610a192d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predictions  Actual\n",
       "0              1       0\n",
       "1              1       0\n",
       "2              1       0\n",
       "3              1       0\n",
       "4              2       0\n",
       "..           ...     ...\n",
       "130            1       5\n",
       "131            1       5\n",
       "132            1       5\n",
       "133            1       5\n",
       "134            1       5\n",
       "\n",
       "[135 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_predic_frame_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "225a903f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 4, 5}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(multi_predic_frame_a.Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3c42886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_acc(df):\n",
    "    precision = []\n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    for i in range(len(set(df.Predictions))):\n",
    "        tp = df[np.logical_and(df['Actual'] == i, df['Predictions'] == i)].shape[0]\n",
    "        tn = df[np.logical_and(df['Actual'] != i, df['Predictions'] != i)].shape[0]\n",
    "        fp = df[np.logical_and(df['Actual'] != i, df['Predictions'] == i)].shape[0]\n",
    "        fn = df[np.logical_and(df['Actual'] == i, df['Predictions'] != i)].shape[0]\n",
    "        print(tp)\n",
    "        print(tn)\n",
    "        print(fp)\n",
    "        print(fn)\n",
    "        total_preds = df.shape[0]\n",
    "        precision.append(tp/(tp + fp))\n",
    "        accuracy.append((tp + tn)/total_preds)\n",
    "        recall.append(tp/(tp + fn))\n",
    "    return(accuracy,precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e8c0658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "0\n",
      "23\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [113], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mprec_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_predic_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(stats[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(stats[\u001b[38;5;241m2\u001b[39m]))\n",
      "Cell \u001b[1;32mIn [112], line 15\u001b[0m, in \u001b[0;36mprec_acc\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(fn)\n\u001b[0;32m     14\u001b[0m total_preds \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m precision\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtp\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mappend((tp \u001b[38;5;241m+\u001b[39m tn)\u001b[38;5;241m/\u001b[39mtotal_preds)\n\u001b[0;32m     17\u001b[0m recall\u001b[38;5;241m.\u001b[39mappend(tp\u001b[38;5;241m/\u001b[39m(tp \u001b[38;5;241m+\u001b[39m fn))\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "stats = prec_acc(multi_predic_frame)\n",
    "print(\"Precision: \" + str(stats[1]))\n",
    "print(\"Recall: \" + str(stats[2]))\n",
    "print(\"Classes: \" + multi_test_name_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0f1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
