{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1619b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from shutil import unpack_archive\n",
    "from collections import OrderedDict\n",
    "from keras_preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd0fae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN (object):\n",
    "    def __init__(self, dataset_path, img_width, img_height, batch_size, epochs, num_classes, model_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def train(self):\n",
    "        # Data augmentation\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        self.read_clean_data()\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            self.dataset_path + \"output/multi_train\",\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        validation_generator = test_datagen.flow_from_directory(\n",
    "            self.dataset_path + \"output/multi_val/\",\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "        testing_generator = test_datagen.flow_from_directory(\n",
    "            self.dataset_path + \"output/multi_test/\",\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical'            \n",
    "        )\n",
    "\n",
    "        # Model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(96, (7, 7), strides=(2, 2), padding='same', input_shape=(self.img_width, self.img_height, 3)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        model.add(Conv2D(256, (1, 1), strides=(1, 1), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        model.add(Conv2D(384, (1, 1), strides=(1, 1), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(4096))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        #modelo de treinamento reconhecimento de faces usando o modelo de treinamento do AlexNet\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        # Training\n",
    "        sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "        checkpointer = ModelCheckpoint(filepath=self.model_path, verbose=1, save_best_only=True)\n",
    "        model.fit_generator( train_generator, \n",
    "                            steps_per_epoch=train_generator.n // self.batch_size, \n",
    "                            epochs=self.epochs, \n",
    "                            validation_data=validation_generator, \n",
    "                            validation_steps=testing_generator.n // self.batch_size, \n",
    "                            callbacks=[checkpointer])\n",
    "\n",
    "        # Save model\n",
    "        model.save(self.model_path)\n",
    "\n",
    "\n",
    "    def predict(self, img_path):\n",
    "        model = keras.models.load_model(self.model_path)\n",
    "        img = image.load_img(img_path, target_size=(self.img_width, self.img_height))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        #x = preprocess_input(x)\n",
    "        preds = model.predict(x)\n",
    "        return preds\n",
    "\n",
    "    def read_clean_data(self):\n",
    "        lfw_allnames = pd.read_csv(self.dataset_path + \"lfw_allnames.csv\")\n",
    "\n",
    "        image_paths = lfw_allnames.loc[lfw_allnames.index.repeat(lfw_allnames['images'])]\n",
    "        image_paths['image_path'] = 1 + image_paths.groupby('name').cumcount()\n",
    "        image_paths['image_path'] = image_paths.image_path.apply(lambda x: '{0:0>4}'.format(x))\n",
    "        image_paths['image_path'] = image_paths.name + \"/\" + image_paths.name + \"_\" + image_paths.image_path + \".jpg\"\n",
    "        image_paths = image_paths.drop(\"images\",axis=1)\n",
    "\n",
    "        multi_data = pd.concat([image_paths[image_paths.name==\"George_W_Bush\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Colin_Powell\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Tony_Blair\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Donald_Rumsfeld\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Gerhard_Schroeder\"].sample(75),\n",
    "                        image_paths[image_paths.name==\"Ariel_Sharon\"].sample(75)])\n",
    "\n",
    "        print(\"Multi_Data \",len(multi_data))\n",
    "\n",
    "        multi_train, multi_test = train_test_split(multi_data, test_size=0.3)\n",
    "        multi_train, multi_val = train_test_split(multi_train,test_size=0.3)\n",
    "\n",
    "        self.directory_mover(multi_train,\"multi_train/\")\n",
    "        self.directory_mover(multi_val,\"multi_val/\")\n",
    "        self.directory_mover(multi_test,\"multi_test/\")\n",
    "\n",
    "\n",
    "    def directory_mover(self,data,dir_name):\n",
    "        co = 0\n",
    "        for image in data.image_path:\n",
    "            # create top directory\n",
    "            if not os.path.exists(os.path.join(self.dataset_path + 'output/',dir_name)):\n",
    "                shutil.os.mkdir(os.path.join(self.dataset_path + 'output/',dir_name))\n",
    "\n",
    "            data_type = data[data['image_path'] == image]['name']\n",
    "            data_type = str(list(data_type)[0])\n",
    "            if not os.path.exists(os.path.join(self.dataset_path + 'output/',dir_name,data_type)):\n",
    "                shutil.os.mkdir(os.path.join(self.dataset_path + 'output/',dir_name,data_type))\n",
    "            path_from = os.path.join(self.dataset_path + 'lfw-deepfunneled/',image)\n",
    "            path_to = os.path.join(self.dataset_path + 'output/',dir_name,data_type)\n",
    "            # print(path_to)\n",
    "            shutil.copy(path_from, path_to)\n",
    "            # print('Moved {} to {}'.format(image,path_to))\n",
    "            co += 1\n",
    "\n",
    "        print('Moved {} images to {} folder.'.format(co,dir_name))\n",
    "\n",
    "\n",
    "    def clean(self):\n",
    "        # Clean image used for testing\n",
    "        if \"multi_train\" in os.listdir(self.dataset_path + \"output/\"):\n",
    "            shutil.rmtree(self.dataset_path + \"output/multi_train\")\n",
    "        if \"multi_val\" in os.listdir(self.dataset_path + \"output/\"):\n",
    "            shutil.rmtree(self.dataset_path + \"output/multi_val\")\n",
    "        if \"multi_test\" in os.listdir(self.dataset_path + \"output/\"):\n",
    "            shutil.rmtree(self.dataset_path + \"output/multi_test\")\n",
    "\n",
    "    def get_stats(self):\n",
    "        multi_test_names = []\n",
    "\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        multi_test_set = test_datagen.flow_from_directory(\n",
    "            self.dataset_path + \"output/multi_test/\",\n",
    "            target_size=(self.img_width, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical'            \n",
    "        )\n",
    "\n",
    "        for i in range(len(multi_test_set.filenames)):\n",
    "            multi_test_names.append(multi_test_set.filenames[i])\n",
    "        for i in range(len(multi_test_names)):\n",
    "            multi_test_names[i] = multi_test_names[i].split(\"/\")[0]\n",
    "\n",
    "        multi_test_name_order = list(OrderedDict.fromkeys(multi_test_names))\n",
    "        for i in range(len(multi_test_name_order)):\n",
    "            multi_test_name_order[i] = multi_test_name_order[i].replace(\"\\\\\",\"/\")\n",
    "            \n",
    "        predictions_values = 0\n",
    "        predictions_len = []\n",
    "        for i in range(len(multi_test_name_order)):\n",
    "            prediction = self.predict(self.dataset_path + \"output/multi_test/\" + multi_test_name_order[i])\n",
    "            predictions_values += prediction\n",
    "            predictions_len += [i] * len(prediction)\n",
    "\n",
    "        \n",
    "        multi_predic_frame = pd.DataFrame(list(zip(predictions_values,predictions_len)), columns=['Predictions','Actual'])\n",
    "        stats = self.prec_acc(multi_predic_frame)\n",
    "        print(\"Precision: \" + str(stats[1]))\n",
    "        print(\"Recall: \" + str(stats[2]))\n",
    "        print(\"Classes: \" + multi_test_name_order);\n",
    "        \n",
    "    def prec_acc(self, df):\n",
    "        precision = []\n",
    "        accuracy = []\n",
    "        recall = []\n",
    "        for i in range(len(set(predictions_frame.Predictions))):\n",
    "            tp = predictions_frame[np.logical_and(predictions_frame['Actual'] == i, predictions_frame['Predictions'] == i)].shape[0]\n",
    "            tn = predictions_frame[np.logical_and(predictions_frame['Actual'] != i, predictions_frame['Predictions'] != i)].shape[0]\n",
    "            fp = predictions_frame[np.logical_and(predictions_frame['Actual'] != i, predictions_frame['Predictions'] == i)].shape[0]\n",
    "            fn = predictions_frame[np.logical_and(predictions_frame['Actual'] == i, predictions_frame['Predictions'] != i)].shape[0]\n",
    "            total_preds = predictions_frame.shape[0]\n",
    "            precision.append(tp/(tp + fp))\n",
    "            accuracy.append((tp + tn)/total_preds)\n",
    "            recall.append(tp/(tp + fn))\n",
    "        return(accuracy,precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bead50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e823d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_test = CNN(\"../dataset/\",250,250,32,14,6,\"../dataset/output/model/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00b142cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1028 images belonging to 6 classes.\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021D8D8F1360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021D8D8B71C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 495ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 484ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 461ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 461ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 439ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcnn_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [75], line 180\u001b[0m, in \u001b[0;36mCNN.get_stats\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m predictions_len \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(multi_test_name_order)):\n\u001b[1;32m--> 180\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/multi_test/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmulti_test_name_order\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     predictions_values \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prediction\n\u001b[0;32m    182\u001b[0m     predictions_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [i] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(prediction)\n",
      "Cell \u001b[1;32mIn [75], line 93\u001b[0m, in \u001b[0;36mCNN.predict\u001b[1;34m(self, img_path)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_path):\n\u001b[1;32m---> 93\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(img_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_height))\n\u001b[0;32m     95\u001b[0m     x \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\keras\\saving\\save.py:231\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m     )\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaved_model_load\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\keras\\saving\\saved_model\\load.py:141\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    138\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load ShardedVariables\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     )\n\u001b[1;32m--> 141\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m keras_loader\u001b[38;5;241m.\u001b[39mfinalize_objects()\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:930\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 930\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_graph_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mckpt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:192\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_all()\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_options\u001b[38;5;241m.\u001b[39mexperimental_skip_checkpoint:\n\u001b[1;32m--> 192\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes:\n\u001b[0;32m    194\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, resource\u001b[38;5;241m.\u001b[39mCapturableResource):\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:510\u001b[0m, in \u001b[0;36mLoader._restore_checkpoint\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    508\u001b[0m   load_status\u001b[38;5;241m.\u001b[39massert_nontrivial_match()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 510\u001b[0m   load_status \u001b[38;5;241m=\u001b[39m \u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m   load_status\u001b[38;5;241m.\u001b[39massert_existing_objects_matched()\n\u001b[0;32m    512\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m load_status\u001b[38;5;241m.\u001b[39m_checkpoint\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:1495\u001b[0m, in \u001b[0;36mTrackableSaver.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1484\u001b[0m object_graph_proto\u001b[38;5;241m.\u001b[39mParseFromString(object_graph_string)\n\u001b[0;32m   1485\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _CheckpointRestoreCoordinator(\n\u001b[0;32m   1486\u001b[0m     object_graph_proto\u001b[38;5;241m=\u001b[39mobject_graph_proto,\n\u001b[0;32m   1487\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1493\u001b[0m     saveables_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saveables_cache)\n\u001b[0;32m   1494\u001b[0m \u001b[43mrestore_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheckpointPosition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m-> 1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# Attached dependencies are not attached to the root, so should be restored\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# separately.\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_view\u001b[38;5;241m.\u001b[39mattached_dependencies:\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\restore.py:55\u001b[0m, in \u001b[0;36mCheckpointPosition.restore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_object(trackable):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# This object's correspondence with a checkpointed object is new, so\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# process deferred restorations for it and its dependencies.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     restore_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_descendants\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m restore_ops:\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mnew_restore_ops(restore_ops)\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\restore.py:458\u001b[0m, in \u001b[0;36mCheckpointPosition._restore_descendants\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m   _queue_children_for_restoration(current_position, visit_queue)\n\u001b[0;32m    455\u001b[0m   _queue_slot_variables(current_position, visit_queue)\n\u001b[0;32m    457\u001b[0m restore_ops\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 458\u001b[0m     \u001b[43mcurrent_position\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_saveables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mpython_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:354\u001b[0m, in \u001b[0;36m_CheckpointRestoreCoordinator.restore_saveables\u001b[1;34m(self, tensor_saveables, python_positions, registered_savers)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor_saveables \u001b[38;5;129;01mor\u001b[39;00m registered_savers:\n\u001b[0;32m    350\u001b[0m   flat_saveables \u001b[38;5;241m=\u001b[39m saveable_object_util\u001b[38;5;241m.\u001b[39mvalidate_and_slice_inputs(\n\u001b[0;32m    351\u001b[0m       tensor_saveables)\n\u001b[0;32m    352\u001b[0m   new_restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDeviceSaver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m      \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, restore_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(new_restore_ops\u001b[38;5;241m.\u001b[39mitems()):\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:403\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    401\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m tf_function_restore()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:385\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore.<locals>.restore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device, saver \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_device_savers\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 385\u001b[0m     restore_ops\u001b[38;5;241m.\u001b[39mupdate(\u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Run registered restore methods after the default restore ops.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (_, restore_fn) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_savers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:104\u001b[0m, in \u001b[0;36m_SingleDeviceSaver.restore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    102\u001b[0m restore_device \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mexperimental_io_device \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(restore_device):\n\u001b[1;32m--> 104\u001b[0m   restored_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mio_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_slices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m structured_restored_tensors \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m    107\u001b[0m     tensor_structure, restored_tensors)\n\u001b[0;32m    108\u001b[0m restore_ops \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:1505\u001b[0m, in \u001b[0;36mrestore_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[0;32m   1503\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1505\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrestore_v2_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_and_slices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m   1509\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:1544\u001b[0m, in \u001b[0;36mrestore_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, dtypes, name, ctx)\u001b[0m\n\u001b[0;32m   1542\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [prefix, tensor_names, shape_and_slices]\n\u001b[0;32m   1543\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtypes)\n\u001b[1;32m-> 1544\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRestoreV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[0;32m   1547\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[0;32m   1548\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestoreV2\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32m~\\Documents\\PUC\\2022_2\\TI\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn_test.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2952d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ac638a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0]*5 + [1]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9546b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f12fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7dea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30c792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d73be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897aba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a836772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f64480",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
